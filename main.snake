"""Snakemake file."""

# See tutorial at: http://tiny.cc/snakemake_tutorial

import os

from pathlib import Path

import yaml

import pandas as pd
import numpy as np

from matplotlib import pyplot as plt
import seaborn as sns
sns.set_style("whitegrid")

from python.functions import *

ORIGINAL_CONFIG_AS_STRING = yaml.dump(config, default_flow_style=False)


#### COMMON RUN SPECIFICS ####

RUN_NAME = config["COMMON"]["RUN_NAME"]
OUT_DIR = Path("{base_dir}/{run_name}".format(base_dir=config["COMMON"]["OUT_DIR_LOCATION"], run_name=RUN_NAME))
LOGS_DIR = OUT_DIR / "logs"

INPUT_ALL = []



############ BEGIN PIPELINE RULES ############


#### SAVE_RUN_CONFIG ####
SAVE_RUN_CONFIG_OUT = OUT_DIR / "{RUN_NAME}.yaml".format(RUN_NAME=RUN_NAME)

rule save_run_config:
    input:
    output:
        file=str(SAVE_RUN_CONFIG_OUT)

    run:
        with open(output.file, 'w') as cnf_out:
            cnf_out.write(ORIGINAL_CONFIG_AS_STRING)

INPUT_ALL.append(rules.save_run_config.output)

# ------------------------- #
#### CREATE_SEQ_DICT ####
CREATE_SEQ_DICT = config["CREATE_SEQ_DICT"]

# log
LOG_CREATE_SEQ_DICT = LOGS_DIR / "create_seq_dict.log"

# input
REF_FASTA = Path(CREATE_SEQ_DICT["REF_FASTA"])

# output
FASTA_DICT = REF_FASTA.parent / "{stem}.dict".format(stem=REF_FASTA.stem)


# ---
rule create_seq_dict:
    log:
        path=str(LOG_CREATE_SEQ_DICT)

    input:
        ref_fasta=str(REF_FASTA),

    output:
        fasta_dict=str(FASTA_DICT),

    shell:
        """ \
        picard CreateSequenceDictionary \
        R={input.ref_fasta} \
        O={output.fasta_dict} \
        &> {log.path} \
        """
INPUT_ALL.append(rules.create_seq_dict.output)

# ------------------------- #
#### CREATE_SEQ_FAI ####
CREATE_SEQ_FAI = config["CREATE_SEQ_FAI"]

# log
LOG_CREATE_SEQ_FAI = LOGS_DIR / "create_seq_fai.log"

# input
REF_FASTA = Path(CREATE_SEQ_FAI["REF_FASTA"])

# output
FASTA_FAI = REF_FASTA.parent / "{fas}.fai".format(fas=REF_FASTA)


# ---
rule create_seq_fai:
    log:
        path=str(LOG_CREATE_SEQ_FAI)

    input:
        ref_fasta=str(REF_FASTA),

    output:
        fasta_fai=str(FASTA_FAI),

    shell:
        "samtools faidx "
        "{input.ref_fasta} "
        "&> {log.path} "

INPUT_ALL.append(rules.create_seq_fai.output)


# ------------------------- #
#### VALIDATE_INPUT_VCFS ####
VALIDATE_INPUT_VCFS = config["VALIDATE_INPUT_VCFS"]

# log
LOG_VALIDATE_INPUT_VCFS = LOGS_DIR / "validate_input_vcfs.log"

# input
INPUT_VCF_DIR = Path(VALIDATE_INPUT_VCFS["INPUT_VCF_DIR"])
INPUT_VCFS = str(INPUT_VCF_DIR / "{vcf}.vcf")

# output
VALIDATE_INPUT_VCFS_SENTINELS = str(OUT_DIR / "validate_input_vcfs" / "{vcf}_validated_on.txt")
VALIDATE_INPUT_VCFS_OUTS_EXPANDED = [VALIDATE_INPUT_VCFS_SENTINELS.format(vcf=vcf.stem) for vcf in INPUT_VCF_DIR.glob("*.vcf")]


# ---
rule validate_input_vcfs:
    log:
        path=str(LOG_VALIDATE_INPUT_VCFS)

    input:
        input_vcfs=INPUT_VCFS,
        ref_fasta=str(REF_FASTA),

    output:
        sentinels=VALIDATE_INPUT_VCFS_SENTINELS,

    shell:
        "gatk -T ValidateVariants "
        "-R {input.ref_fasta} "
        "-V {input.input_vcfs} "
        "--warnOnErrors "
        "--validationTypeToExclude ALL "
        "&> {log.path} "
        "&& echo $(date) > {output.sentinels}"

INPUT_ALL.append(VALIDATE_INPUT_VCFS_OUTS_EXPANDED)

# ------------------------- #


#### ALL ####
# ---
rule all:
    input: INPUT_ALL
